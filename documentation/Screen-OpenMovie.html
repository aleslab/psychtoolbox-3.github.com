<h1 id="screenopenmovie"><a href="Screen-OpenMovie">Screen(‘OpenMovie’)</a></h1>
<h2 id="psychtoolbox-screen.mexdll-subfunction">[[Psychtoolbox]] › [[Screen]].{mex*,dll} subfunction</h2>
<p>Try to open the multimediafile ‘moviefile’ for playback in onscreen window<br />
‘windowPtr’ and return a handle ‘moviePtr’ on success.<br />
This function requires the [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) multi-media framework to be installed on<br />
your system.<br />
The following movie properties are optionally returned: ‘duration’ Total<br />
duration of movie in seconds. ‘fps’ Video playback framerate, assuming a linear<br />
spacing of videoframes in time. There may exist exotic movie formats which don’t<br />
have this linear spacing. In that case, ‘fps’ would return bogus values and the<br />
check for skipped frames would report bogus values as well. ‘width’ Width of the<br />
images contained in the movie. ‘height’ Height of the images.<br />
‘count’ Total number of videoframes in the movie. Determined by counting, so<br />
querying ‘count’ can significantly increase the execution time of this command.<br />
‘aspectRatio’ Pixel aspect ratio of pixels in the video frames. Typically 1.0<br />
for square pixels.<br />
If you want to play multiple movies in succession with lowest possible delay<br />
inbetween the movies then you can ask PTB to load a movie in the background<br />
while another movie is still playing: Call this function with the ‘async’ flag<br />
set to 1. This will initiate the background load operation. After some<br />
sufficient time has passed, you can call the ‘OpenMovie’ function again, this<br />
time with the ‘async’ flag set to zero. Now the function will return a valid<br />
movie handle for playback.<br />
If all your movies have exactly the same format and only differ in duration and<br />
content, but not in image size, color depth, encoding format, or fps, then you<br />
can also use an aync setting of 2 and provide the ‘moviePtr’ handle of an<br />
already opened movie in the ‘preloadSecs’ parameter. This will queue the movie<br />
‘moviefile’ as a successor to the currently playing moviefile in ‘moviePtr’.<br />
Queuing movies this way is more efficient than async flag setting 1, although<br />
also more restricted.<br />
If the ‘async’ flag also contains the number 4 or is equal to 4, then movie<br />
playback will not automatically drop video frames to preserve audio-video sync<br />
in case fetching and display of video frames by your script is delayed or too<br />
slow. This has the disadvantage that you’ll need to take care of audio-video<br />
sync and framerate control yourself by proper comparison of movie presentation<br />
timestamps and <a href="GetSecs" class="uri">GetSecs</a> or <a href="Screen" class="uri">Screen</a>(‘<a href="Flip" class="uri">Flip</a>’) timestamps. The advantage is, that<br />
after start of playback the playback engine can internally predecode and buffer<br />
up to ‘preloadSecs’ seconds worth of video and audio data. This may allow<br />
complex movies to play more smoothly or at higher framerates.<br />
‘preloadSecs’ This optional parameter allows to ask <a href="Screen" class="uri">Screen</a>() to buffer at least<br />
up to ‘preloadSecs’ seconds of the movie. This potentially allows for more<br />
stutter-free playback, but your mileage may vary, depending on movie format,<br />
storage medium and lots of other factors. In most cases, the default setting is<br />
perfectly sufficient. The special setting -1 means: Try to buffer the whole<br />
movie. Caution: Long movies may cause your system to run low on memory or disc<br />
space and have disastrous effects on playback performance! Also, the exact type<br />
of buffering applied depends a lot on the movie playback engine and movie<br />
format, but it usually affects the buffering behaviour and capacity of buffering<br />
in some meaningful way.<br />
‘specialFlags1’ Optional flags, numbers to be added together: 1 = Use YUV video<br />
decoding instead of RGBA, if supported by movie codec and GPU - May be more<br />
efficient. 2 = Don’t decode and use sound - May be more efficient. On Linux you<br />
may need to specify a setting of 2 if you try to use movie playback at the same<br />
time as <a href="PsychPortAudio" class="uri">PsychPortAudio</a> sound output, otherwise movie playback may hang. A flag<br />
of 4 will draw motion vectors on top of decoded video frames, for debugging or<br />
entertainment. A flag of 8 will ask the video decoder to skip all B-Frames<br />
during decoding to reduce processor load on very slow machines. Not all codecs<br />
may support flags 4 or 8, in which case these flags are silently ignored. A flag<br />
of 16 asks <a href="Screen" class="uri">Screen</a> to convert all video textures immediately into a format which<br />
makes them useable as offscreen windows, and for the <a href="Screen" class="uri">Screen</a>(‘TransformTexture’)<br />
function as well as for drawing them with your own custom GLSL shaders. Normally<br />
this conversion would be deferred until needed, ie. it would get skipped if you<br />
would just draw the texture regularly. If you know already that you want to use<br />
the texture with one of the given functions, manually triggering the conversion<br />
via this flag may be a bit more efficient - or convenient if you want to use<br />
your own GLSL shaders.<br />
The optional flags 32, 64 and 128 influence how looped playback is performed if<br />
usercode requests such repetitive playback via <a href="Screen" class="uri">Screen</a>(‘PlayMovie’, …) with the<br />
‘loop’ flag set to one. Different strategies exist to handle different quirks<br />
with some movie file formats and encodings and some versions of [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)): A<br />
flag of 32 requests looped playback via gapless reloading of the movie instead<br />
of rewinding it to the start. A flag of 64 uses so called segment seeks for<br />
rewinding, a flag of 128 asks to flush the video pipeline during rewinding. Your<br />
mileage with these looping strategies will differ, but usually the default<br />
settings are good enough for most purposes.<br />
A ‘specialFlags1’ setting of 256 will prevent automatic deinterlacing of video.<br />
This is useful to prevent some internal color data conversions, e.g., of pure<br />
grayscale data, which can cause slightly lossy decoding of lossless video data.<br />
A ‘specialFlags1’ setting of 512 marks the movie as encoded in Psychtoolbox’s<br />
own proprietary 16 bpc high precision format. Grayscale movies in this format<br />
can be created by specifying the keyword <a href="UsePTB16BPC" class="uri">UsePTB16BPC</a> in <a href="Screen" class="uri">Screen</a>(‘CreateMovie’) or<br />
in the firewire videocapture engine as part of the codec spec string. RGB movies<br />
can also get created this way. Encoding or decoding of such 16 bpc movies with a<br />
channel count other than 1 or 3 for gray or RGB is not supported.<br />
A ‘specialFlags1’ setting of 1024 tells the movie playback that this movies<br />
video frames are encoded as raw Bayer sensor data and that they should get<br />
converted to RGB images during playback via software Bayer filtering. You must<br />
set the ‘pixelFormat’ parameter to 1 for this to work. You can choose the Bayer<br />
filtering method via ‘DebayerMethod’ setting and the color sensor filter pattern<br />
via ‘OverrideBayerPattern’ setting in <a href="Screen" class="uri">Screen</a>(‘SetVideoCaptureParameter’, -1,<br />
…). By default, fast nearest neighbour debayering with an assumed sensor image<br />
layout of RGGB is performed.<br />
‘pixelFormat’ optional argument specifying the pixel format of decoded video<br />
frames. Not all possible valid values are supported by all video codecs,<br />
graphics cards and operating systems. If an unsupported format is requested,<br />
<a href="Screen" class="uri">Screen</a>() will try to choose the closest matching format that meets or exceeds<br />
the specified format, at a performance or efficiency penalty. If no sufficiently<br />
close match is possible without severely degraded performance or other<br />
restrictions, the function will abort with an error. The following formats are<br />
supported on some setups: 1 = Luminance/Greyscale image, 2 = Luminance+Alpha, 3<br />
= RGB 8 bit per channel, 4 = RGBA8, 5 = YUV 4:2:2 packed pixel format on some<br />
graphics hardware, 6 = YUV-I420 planar format, using GLSL shaders for color<br />
space conversion on suitable graphics cards. 7 or 8 = Y8-Y800 planar format,<br />
using GLSL shaders, 9 = 16 bit Luminance, 10 = 16 bpc RGBA image.The always<br />
supported default is ‘4’ == RGBA8 format. A setting of 6 (for color) or 7/8 (for<br />
grayscale) for selection of YUV-I420/Y8-Y800 format, as supported by at least<br />
the H264 and <a href="HuffYUV" class="uri">HuffYUV</a> video codecs on any GPU with shader support, can be<br />
especially efficient for fast playback of high resolution video. As this format<br />
uses shaders for post-processing, it should be fast for texture drawing, but can<br />
incur significant overhead if you try to draw into a texture of this format, or<br />
try to post-process it via <a href="Screen" class="uri">Screen</a>(‘TransformTexture’). If you try to attach your<br />
own shaders to such a texture during <a href="Screen" class="uri">Screen</a>(‘DrawTexture’), you will need to<br />
implement color conversion yourself in your shaders, as your shaders would<br />
override <a href="Screen" class="uri">Screen</a>‘s builtin color conversion shader.<br />
’maxNumberThreads’ Optional parameter which allows to set the maximum number of<br />
parallel processing threads that should be used by multi-threaded video codecs<br />
to decode the movie. The parameter has no effect on single threaded codecs and<br />
default behaviour is to let the codec do whatever it wants. A setting of zero<br />
tells the codec to use multi-threaded decoding with a number of threads that is<br />
auto-selected to be optimal for your given computer. A number n greater zero<br />
asks the codec to use at most n threads for decoding. The most safe choice is to<br />
not specify this parameter - this should work even with problematic movie<br />
formats. If you need higher playback performance, e.g., for high resolution<br />
video or high framerate playback, you should set the parameter to zero to allow<br />
the optimal choice to the video codec. This should work flawlessly with well<br />
encoded high quality movie files and can provide a significant performance boost<br />
on multi-core computers. Specify a discrete non-zero number of threads if you<br />
want to benefit from multi-core decoding but want to prevent movie playback from<br />
using up all available computation power, e.g., because you want to run some<br />
other timing-sensitive tasks in parallel and want to make sure to leave some<br />
processor cores dedicated to them.<br />
‘movieOptions’ Optional text string which encodes additional options for<br />
playback of the movie. Parameters are keyword=value pairs, separated by three<br />
colons ::: if there are multiple parameters. Currently supported keywords:<br />
<a href="AudioSink" class="uri">AudioSink</a>=<a href="GStreamerSinkSpec" class="uri">GStreamerSinkSpec</a> – <a href="GStreamerSinkSpec" class="uri">GStreamerSinkSpec</a> is a [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) gst-launch line<br />
style specification for a audio sink plugin and its parameters. This allows to<br />
customize where the audio of a movie is sent during playback and with which<br />
parameters. By default, the autoaudiosink plugin is used, which automatically<br />
chooses audio output and parameters, based on your system and user settings.<br />
Most often this is what you want. Sometimes you may want to have more control<br />
over outputs, e.g., if your system has multiple sound cards installed and you<br />
want to route audio output to a specific card and output connector. Example use<br />
of the parameter: ‘AudioSink=pulseaudiosink device=MyCardsOutput1’ would use the<br />
Linux pulseaudiosink plugin to send sound data to the output named<br />
‘MyCardsOutput1’ via the <a href="PulseAudio" class="uri">PulseAudio</a> sound server commonly used on Linux desktop<br />
systems.<br />
If you set a <a href="Screen" class="uri">Screen</a>() verbosity level of 4 or higher, <a href="Screen" class="uri">Screen</a>() will print out<br />
the actually used audio output at the end of movie playback on operating systems<br />
which support this. This can help debugging issues with audio routing if you<br />
don’t hear sound.</p>
<p>&lt;&lt;=====See also:===== CloseMovie PlayMovie GetMovieImage GetMovieTimeIndex SetMovieTimeIndex &lt;&lt;</p>
