<h2 id="psychtoolbox-psychhardware-psychvrtoolbox">[[Psychtoolbox]] › [[PsychHardware]] › [[PsychVRToolbox]]</h2>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a> - A high level driver for VR hardware supported via <a href="OpenHMD" class="uri">OpenHMD</a>.</p>
<p>Note: If you want to write VR code that is portable across<br />
VR headsets of different vendors, then use the <a href="PsychVRHMD" class="uri">PsychVRHMD</a>()<br />
driver instead of this driver. The <a href="PsychVRHMD" class="uri">PsychVRHMD</a> driver will use<br />
this driver as appropriate when connecting to a <a href="OpenHMD" class="uri">OpenHMD</a> supported<br />
device, but it will also automatically work with other head mounted<br />
displays. This driver may expose a few functions specific to <a href="OpenHMD" class="uri">OpenHMD</a>,<br />
so you can mix calls to this driver with calls to <a href="PsychVRHMD" class="uri">PsychVRHMD</a>.</p>
<h3 id="setup-instructions">Setup instructions:</h3>
<p>This driver needs libopenhmd.so version 0.3 or later to be installed<br />
in a linker accessible path (e.g., /usr/local/lib/ on a Linux system).<br />
You can either download, compile and install it from …</p>
<p>https://github.com/<a href="OpenHMD" class="uri">OpenHMD</a>/<a href="OpenHMD" class="uri">OpenHMD</a></p>
<h3 id="or-get-a-precompiled-library-for-libopenhmd.so-from">… or get a precompiled library for libopenhmd.so from:</h3>
<p><a href="RaspberryPi" class="uri">RaspberryPi</a>/Raspbian: https://github.com/Psychtoolbox-3/<a href="MiscStuff" class="uri">MiscStuff</a>/tree/master/<a href="OpenHMD32BitRaspbianARMv7" class="uri">OpenHMD32BitRaspbianARMv7</a></p>
<p>64-Bit Intel/Ubuntu: https://github.com/Psychtoolbox-3/<a href="MiscStuff" class="uri">MiscStuff</a>/tree/master/<a href="OpenHMD64BitIntelUbuntuLinux" class="uri">OpenHMD64BitIntelUbuntuLinux</a></p>
<p>Follow instructions in the accompanying Readme.txt files.</p>
<p>libopenhmd.so in turn needs libhidapi-libusb.so to be installed in<br />
a similar path. On Debian GNU/Linux based systems you can install HIDAPI<br />
via the package libhidapi-libusb0 (apt-get install libhidapi-libusb0).</p>
<p>From the same URL above, you need to get openhmdkeepalivedaemon, an executable<br />
file, and make sure it gets started during system boot of your machine. This so<br />
the HMD gets correctly detected as video output by the X-Server and by Psychtoolbox,<br />
otherwise stimuli may not display on the HMD, but on your regular display. This<br />
executable is not needed for the Oculus Rift DK1 or DK2.</p>
<p>LIMITATIONS: This driver is currently considered BETA quality and may<br />
undergo backwards incompatible changes without prior warning or notice.<br />
Use at your own risk!</p>
<h3 id="usage">Usage:</h3>
<p>hmd = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘AutoSetupHMD’ [, basicTask=‘Tracked3DVR’][, basicRequirements][, basicQuality=0][, deviceIndex]);<br />
- Open a <a href="OpenHMD" class="uri">OpenHMD</a> supported HMD, set it up with good default rendering and<br />
display parameters and generate a <a href="PsychImaging" class="uri">PsychImaging</a>(‘AddTask’, …)<br />
line to setup the Psychtoolbox imaging pipeline for proper display<br />
on the HMD. This will also cause the device connection to get<br />
auto-closed as soon as the onscreen window which displays on<br />
the HMD is closed. Returns the ‘hmd’ handle of the HMD on success.</p>
<p>By default, the first detected HMD will be used and if no VR HMD<br />
is connected, it will open an emulated/simulated one for basic<br />
testing and debugging. You can override this default choice of<br />
HMD by specifying the optional ‘deviceIndex’ parameter to choose<br />
a specific HMD.</p>
<p>More optional parameters: ‘basicTask’ what kind of task should be implemented.<br />
The default is ‘Tracked3DVR’, which means to setup for stereoscopic 3D<br />
rendering, driven by head motion tracking, for a fully immersive experience<br />
in some kind of 3D virtual world. This is the default if omitted. The task<br />
‘Stereoscopic’ sets up for display of stereoscopic stimuli, but without<br />
head tracking. ‘Monoscopic’ sets up for display of monocular stimuli, ie.<br />
the HMD is just used as a special kind of standard display monitor. Please<br />
note that the Oculus Rift DK2 has a special video mode for such monoscopic<br />
presentation: If you set the video mode to 1080x948@120 Hz, then the DK2<br />
will only display a monoscopic image identical to both eyes, but at a refresh<br />
rate of 120 Hz. This allows you to (ab)use the DK2 as a high-speed 120 Hz<br />
monitor!</p>
<p>‘basicRequirements’ defines basic requirements for the task. Currently<br />
defined are the following strings which can be combined into a single<br />
‘basicRequirements’ string: ‘LowPersistence’ = Try to keep exposure<br />
time of visual images on the retina low if possible, ie., try to approximate<br />
a pulse-type display instead of a hold-type display if possible. This has<br />
no effect at the moment for this driver and its supported devices.</p>
<p>‘PerEyeFOV’ = Request use of per eye individual and asymmetric fields of view even<br />
when the ‘basicTask’ was selected to be ‘Monoscopic’ or ‘Stereoscopic’. This allows<br />
for wider field of view in these tasks, but requires the usercode to adapt to these<br />
different and asymmetric fields of view for each eye, e.g., by selecting proper 3D<br />
projection matrices for each eye.</p>
<p>‘FastResponse’ = Try to switch images with minimal delay and fast<br />
pixel switching time. This does nothing on this driver at the moment.</p>
<p>‘TimingSupport’ = Support some hardware specific means of timestamping<br />
or latency measurements. This does nothing on this driver at the moment.</p>
<p>‘TimeWarp’ = Enable per eye image 2D timewarping via prediction of eye<br />
poses at scanout time. This mostly only makes sense for head-tracked 3D<br />
rendering. Depending on ‘basicQuality’ a more cheap or more expensive<br />
procedure is used. This does nothing on this driver at the moment.</p>
<p>‘basicQuality’ defines the basic tradeoff between quality and required<br />
computational power. A setting of 0 gives lowest quality, but with the<br />
lowest performance requirements. A setting of 1 gives maximum quality at<br />
maximum computational load. Values between 0 and 1 change the quality to<br />
performance tradeoff.</p>
<p>hmd = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘Open’ [, deviceIndex], …);<br />
- Open HMD with index ‘deviceIndex’. See <a href="PsychOpenHMDVRCore" class="uri">PsychOpenHMDVRCore</a> Open?<br />
for help on additional parameters.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetAutoClose’, hmd, mode);<br />
- Set autoclose mode for HMD with handle ‘hmd’. ‘mode’ can be<br />
0 (this is the default) to not do anything special. 1 will close<br />
the HMD ‘hmd’ when the onscreen window is closed which displays<br />
on the HMD. 2 will do the same as 1, but close all open <a href="HMDs" class="uri">HMDs</a> and<br />
shutdown the complete driver and <a href="OpenHMD" class="uri">OpenHMD</a> runtime - a full cleanup.</p>
<p>isOpen = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘IsOpen’, hmd);<br />
- Returns 1 if ‘hmd’ corresponds to an open HMD, 0 otherwise.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘<a href="Close" class="uri">Close</a>’ [, hmd])<br />
- <a href="Close" class="uri">Close</a> provided HMD device ‘hmd’. If no ‘hmd’ handle is provided,<br />
all <a href="HMDs" class="uri">HMDs</a> will be closed and the driver will be shutdown.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘Controllers’, hmd);<br />
- Return a bitmask of all connected controllers: Can be the bitand<br />
of the OVR.<a href="ControllerType" class="uri">ControllerType</a>_XXX flags described in ‘GetInputState’.<br />
This does not detect if controllers are hot-plugged or unplugged after<br />
the HMD was opened. Iow. only probed at ‘Open’.<br />
As the current <a href="OpenHMD" class="uri">OpenHMD</a> driver does not support dedicated controllers at the<br />
moment, this always returns 0.</p>
<p>info = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetInfo’, hmd);<br />
- Retrieve a struct ‘info’ with information about the HMD ‘hmd’.<br />
The returned info struct contains at least the following standardized<br />
fields with information:<br />
handle = Driver internal handle for the specific HMD.<br />
driver = Function handle to the actual driver for the HMD, e.g., @<a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>.<br />
type = Defines the type/vendor of the device, e.g., ‘OpenHMD’.<br />
modelName = Name string with the name of the model of the device, e.g., ‘Rift (DK2)’.<br />
separateEyePosesSupported = 1 if use of <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetEyePose’) will improve<br />
the quality of the VR experience, 0 if no improvement<br />
is to be expected, so ‘GetEyePose’ can be avoided<br />
to save processing time without a loss of quality.<br />
This always returns 0 on this driver.</p>
<p>The returned struct may contain more information, but the fields mentioned<br />
above are the only ones guaranteed to be available over the long run. Other<br />
fields may disappear or change their format and meaning anytime without<br />
warning.</p>
<p>isSupported = <a href="PsychOpenHMDVRCore" class="uri">PsychOpenHMDVRCore</a>(‘Supported’);<br />
- Returns 1 if the <a href="OpenHMD" class="uri">OpenHMD</a> driver is functional, 0 otherwise. The<br />
driver is functional if the <a href="OpenHMD" class="uri">OpenHMD</a> runtime library was successfully<br />
initialized. It would return 0 if the required runtime library would<br />
not be correctly installed.</p>
<p>[isVisible, playAreaBounds, <a href="OuterAreaBounds" class="uri">OuterAreaBounds</a>] = <a href="PsychOpenHMDVRCore" class="uri">PsychOpenHMDVRCore</a>(‘VRAreaBoundary’, hmd [, requestVisible]);<br />
- Request visualization of the VR play area boundary for ‘hmd’ and returns its<br />
current extents.</p>
<p>As VR area boundaries are not actually supported by this <a href="OpenHMD" class="uri">OpenHMD</a> driver,<br />
this function returns no-op results, compatible with what other drivers<br />
would return if their guardian system would not be set up.</p>
<p>The input flag ‘requestVisible’ is silently ignored:<br />
‘requestVisible’ 1 = Request showing the boundary area markers, 0 = Don’t<br />
request showing the markers.</p>
<p>Returns in ‘isVisible’ the current visibility status of the VR area boundaries.<br />
This is always 0 for “invisible”.</p>
<p>‘playAreaBounds’ is an empty matrix defining the play area boundaries. The empty<br />
return argument means that the play area is so far undefined on this driver.</p>
<p>‘OuterAreaBounds’ defines the outer area boundaries in the same way as<br />
‘playAreaBounds’. In other words, it always returns an empty matrix.</p>
<p>input = <a href="PsychOpenHMDVRCore" class="uri">PsychOpenHMDVRCore</a>(‘GetInputState’, hmd, controllerType);<br />
- Get input state of controller ‘controllerType’ associated with HMD ‘hmd’.</p>
<p>As this driver does not actually support special VR controllers, only a minimally<br />
useful ‘input’ state is returned for compatibility with other drivers, which is<br />
based on emulating or faking input from real controllers, so this function will be<br />
of limited use. Specifically, only the input.Time and input.Buttons fields are<br />
returned, all other fields are missing. input.Buttons maps defined OVR.Button_XXX<br />
fields to similar or corresponding buttons on the regular keyboard.</p>
<p>‘controllerType’ can be one of OVR.<a href="ControllerType" class="uri">ControllerType</a>_LTouch, OVR.<a href="ControllerType" class="uri">ControllerType</a>_RTouch,<br />
OVR.<a href="ControllerType" class="uri">ControllerType</a>_Touch, OVR.<a href="ControllerType" class="uri">ControllerType</a>_Remote, OVR.<a href="ControllerType" class="uri">ControllerType</a>_XBox, or<br />
OVR.<a href="ControllerType" class="uri">ControllerType</a>_Active for selecting whatever controller is currently active.</p>
<p>Return argument ‘input’ is a struct with fields describing the state of buttons and<br />
other input elements of the specified ‘controllerType’. It has the following fields:</p>
<p>‘Time’ Time of last input state change of controller.<br />
‘Buttons’ Vector with button state on the controller, similar to the ‘keyCode’<br />
vector returned by <a href="KbCheck" class="uri">KbCheck</a>() for regular keyboards. Each position in the vector<br />
reports pressed (1) or released (0) state of a specific button. Use the OVR.Button_XXX<br />
constants to map buttons to positions.</p>
<p>pulseEndTime = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘HapticPulse’, hmd, controllerType [, duration=2.5][, freq=1.0][, amplitude=1.0]);<br />
- Fake triggering a haptic feedback pulse. This does nothing, but return a made up<br />
but consistent ‘pulseEndTime’, as this <a href="OpenHMD" class="uri">OpenHMD</a> driver currently does not support<br />
haptic feedback.</p>
<p>state = <a href="PsychOpenHMDVRCore" class="uri">PsychOpenHMDVRCore</a>(‘PrepareRender’, hmd [, userTransformMatrix][, reqmask=1][, targetTime]);<br />
- Mark the start of the rendering cycle for a new 3D rendered stereoframe.<br />
Return a struct ‘state’ which contains various useful bits of information<br />
for 3D stereoscopic rendering of a scene, based on head tracking data.</p>
<p>‘hmd’ is the handle of the HMD which delivers tracking data and receives the<br />
rendered content for display.</p>
<p>‘reqmask’ defines what kind of information is requested to be returned in<br />
struct ‘state’. Only query information you actually need, as computing some<br />
of this info is expensive! See below for supported values for ‘reqmask’.</p>
<p>‘targetTime’ is the expected time at which the rendered frame will display.<br />
This could potentially be used by the driver to make better predictions of<br />
camera/eye/head pose for the image. Omitting the value will use a target time<br />
that is implementation specific, but known to give generally good results,<br />
e.g., the midpoint of scanout of the next video frame.</p>
<p>‘userTransformMatrix’ is an optional 4x4 right hand side (RHS) transformation<br />
matrix. It gets applied to the tracked head pose as a global transformation<br />
before computing results based on head pose like, e.g., camera transformations.<br />
You can use this to translate the “virtual head” and thereby the virtual eyes/<br />
cameras in the 3D scene, so observer motion is not restricted to the real world<br />
tracking volume of your headset. A typical ‘userTransformMatrix’ would be a<br />
combined translation and rotation matrix to position the observer at some<br />
3D location in space, then define his/her global looking direction, aka as<br />
heading angle, yaw orientation, or rotation around the y-axis in 3D space.<br />
Head pose tracking results would then operate relative to this global transform.<br />
If ‘userTransformMatrix’ is left out, it will default to an identity transform,<br />
in other words, it will do nothing.</p>
<p>state always contains a field state.tracked, whose bits signal the status<br />
of head tracking for this frame. A +1 flag means that head orientation is<br />
tracked. A +2 flag means that head position is tracked via some absolute<br />
position tracker like, e.g., the <a href="OpenHMD" class="uri">OpenHMD</a> Rift DK2 camera. We also return a +128<br />
flag which means the HMD is actually strapped onto the subjects head and displaying<br />
our visual content. We can’t detect actual HMD display state, but do this for<br />
compatibility to other drivers.</p>
<p>state also always contains a field state.<a href="SessionState" class="uri">SessionState</a>, whose bits signal general<br />
VR session status. In our case we always return +7 on this <a href="OpenHMD" class="uri">OpenHMD</a> driver, as we<br />
can’t detect <a href="ShouldQuit" class="uri">ShouldQuit</a>, <a href="ShouldRecenter" class="uri">ShouldRecenter</a> or <a href="DisplayLost" class="uri">DisplayLost</a> conditions, neither if the<br />
HMD is strapped to the users head.</p>
<p>+1 = Our rendering goes to the HMD, ie. we have control over it. Lack of this could<br />
mean the Health and Safety warning is displaying at the moment and waiting for<br />
acknowledgement, or some other application is in control.<br />
+2 = HMD is present and active.<br />
+4 = HMD is strapped onto users head.<br />
+8 = <a href="DisplayLost" class="uri">DisplayLost</a> condition! Some hardware/software malfunction, need to completely<br />
quit this Psychtoolbox session to recover from this.<br />
+16 = <a href="ShouldQuit" class="uri">ShouldQuit</a> The user interface / user asks us to voluntarily terminate this session.<br />
+32 = <a href="ShouldRecenter" class="uri">ShouldRecenter</a> = The user interface asks us to recenter/recalibrate our tracking origin.</p>
<h3 id="reqmask-defaults-to-1-and-can-have-the-following-values-added-together">‘reqmask’ defaults to 1 and can have the following values added together:</h3>
<p>+1 = Return matrices for left and right “eye cameras” which can be directly<br />
used as <a href="OpenGL" class="uri">OpenGL</a> GL_MODELVIEW matrices for rendering the scene. 4x4 matrices<br />
for left- and right eye are contained in state.modelView{1} and {2}.</p>
<pre><code> Return position and orientation 4x4 camera view matrices which describe  
 position and orientation of the &quot;eye cameras&quot; relative to the world  
 reference frame. They are the inverses of state.modelView{}. These  
 matrices can be directly used to define cameras for rendering of complex  
 3D scenes with the [Horde3D](Horde3D) 3D engine. Left- and right eye matrices are  
 contained in state.cameraView{1} and {2}.  

 Additionally tracked/predicted head pose is returned in state.localHeadPoseMatrix  
 and the global head pose after application of the &#39;userTransformMatrix&#39; is  
 returned in state.globalHeadPoseMatrix - this is the basis for computing  
 the camera transformation matrices.  </code></pre>
<p>+2 = Return matrices for tracked left and right hands of user, ie. of tracked positions<br />
and orientations of left and right hand tracking controllers, if any. As this <a href="OpenHMD" class="uri">OpenHMD</a><br />
driver does not support hand tracking, this reports hard-coded neutral results and<br />
reports a state.handStatus of 0 = “Not tracked/Invalid data”.</p>
<pre><code> state.handStatus(1) = Tracking status of left hand: 0 = Untracked, signalling that  
                       all the following information is invalid and can not be used  
                       in any meaningful way.  

 state.handStatus(2) = Tracking status of right hand. 0 = Untracked.  

 state.localHandPoseMatrix{1} = 4x4 [OpenGL](OpenGL) right handed reference frame matrix with  
                                hand position and orientation encoded to define a  
                                proper GL\_MODELVIEW transform for rendering stuff  
                                &quot;into&quot;/&quot;relative to&quot; the oriented left hand. Always  
                                a 4x4 unit identity matrix for hand resting in origin.  

 state.localHandPoseMatrix{2} = Ditto for the right hand.  

 state.globalHandPoseMatrix{1} = userTransformMatrix \* state.localHandPoseMatrix{1};  
                                 Left hand pose transformed by passed in userTransformMatrix.  

 state.globalHandPoseMatrix{2} = Ditto for the right hand.  

 state.globalHandPoseInverseMatrix{1} = Inverse of globalHandPoseMatrix{1} for collision  
                                        testing/grasping of virtual objects relative to  
                                        hand pose of left hand.  

 state.globalHandPoseInverseMatrix{2} = Ditto for right hand.  </code></pre>
<p>More flags to follow…</p>
<p>eyePose = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetEyePose’, hmd, renderPass [, userTransformMatrix][, targetTime]);<br />
- Return a struct ‘eyePose’ which contains various useful bits of information<br />
for 3D stereoscopic rendering of the stereo view of one eye, based on head<br />
tracking data. This function provides essentially the same information as<br />
the ‘PrepareRender’ function, but only for one eye. Therefore you will need<br />
to call this function twice, once for each of the two renderpasses, at the<br />
beginning of each renderpass. Note: Currently there is no advantage to using<br />
this function on top of ‘PrepareRender’, it only increases overhead and is here<br />
only for compatibility with other drivers.</p>
<p>‘hmd’ is the handle of the HMD which delivers tracking data and receives the<br />
rendered content for display.</p>
<p>‘renderPass’ defines if information should be returned for the 1st renderpass<br />
(renderPass == 0) or for the 2nd renderpass (renderPass == 1). The driver will<br />
decide for you if the 1st renderpass should render the left eye and the 2nd<br />
pass the right eye, or if the 1st renderpass should render the right eye and<br />
then the 2nd renderpass the left eye. The ordering depends on the properties<br />
of the video display of your HMD, specifically on the video scanout order:<br />
Is it right to left, left to right, or top to bottom? For each scanout order<br />
there is an optimal order for the renderpasses to minimize perceived lag.</p>
<p>‘targetTime’ is the expected time at which the rendered frame will display.<br />
This could potentially be used by the driver to make better predictions of<br />
camera/eye/head pose for the image. Omitting the value will use a target time<br />
that is implementation specific, but known to give generally good results.</p>
<p>‘userTransformMatrix’ is an optional 4x4 right hand side (RHS) transformation<br />
matrix. It gets applied to the tracked head pose as a global transformation<br />
before computing results based on head pose like, e.g., camera transformations.<br />
You can use this to translate the “virtual head” and thereby the virtual eyes/<br />
cameras in the 3D scene, so observer motion is not restricted to the real world<br />
tracking volume of your headset. A typical ‘userTransformMatrix’ would be a<br />
combined translation and rotation matrix to position the observer at some<br />
3D location in space, then define his/her global looking direction, aka as<br />
heading angle, yaw orientation, or rotation around the y-axis in 3D space.<br />
Head pose tracking results would then operate relative to this global transform.<br />
If ‘userTransformMatrix’ is left out, it will default to an identity transform,<br />
in other words, it will do nothing.</p>
<h3 id="return-values-in-struct-eyepose">Return values in struct ‘eyePose’:</h3>
<p>‘eyeIndex’ The eye for which this information applies. 0 = Left eye, 1 = Right eye.<br />
You can pass ‘eyeIndex’ into the <a href="Screen" class="uri">Screen</a>(‘SelectStereoDrawBuffer’, win, eyeIndex)<br />
to select the proper eye target render buffer.</p>
<p>‘modelView’ is a 4x4 RHS <a href="OpenGL" class="uri">OpenGL</a> matrix which can be directly used as <a href="OpenGL" class="uri">OpenGL</a><br />
GL_MODELVIEW matrix for rendering the scene.</p>
<p>‘cameraView’ contains a 4x4 RHS camera matrix which describes position and<br />
orientation of the “eye camera” relative to the world reference<br />
frame. It is the inverse of eyePose.modelView. This matrix can<br />
be directly used to define the camera for rendering of complex<br />
3D scenes with the <a href="Horde3D" class="uri">Horde3D</a> 3D engine or other engines which want<br />
absolute camera pose instead of the inverse matrix.</p>
<p>Additionally tracked/predicted head pose is returned in eyePose.localHeadPoseMatrix<br />
and the global head pose after application of the ‘userTransformMatrix’ is<br />
returned in eyePose.globalHeadPoseMatrix - this is the basis for computing<br />
the camera transformation matrix.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetupRenderingParameters’, hmd [, basicTask=‘Tracked3DVR’][, basicRequirements][, basicQuality=0][, fov=[<a href="HMDRecommended" class="uri">HMDRecommended</a>]][, pixelsPerDisplay=1])<br />
- Query the HMD ‘hmd’ for its properties and setup internal rendering<br />
parameters in preparation for opening an onscreen window with <a href="PsychImaging" class="uri">PsychImaging</a><br />
to display properly on the HMD. See section about ‘AutoSetupHMD’ above for<br />
the meaning of the optional parameters ‘basicTask’, ‘basicRequirements’<br />
and ‘basicQuality’.</p>
<p>‘fov’ Optional field of view in degrees, from line of sight: [leftdeg, rightdeg,<br />
updeg, downdeg]. If ‘fov’ is omitted, the HMD runtime will be asked for a<br />
good default field of view and that will be used. The field of view may be<br />
dependent on the settings in the HMD user profile of the currently selected<br />
user.</p>
<p>‘pixelsPerDisplay’ Ratio of the number of render target pixels to display pixels<br />
at the center of distortion. Defaults to 1.0 if omitted. Lower values can<br />
improve performance, at lower quality.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetBasicQuality’, hmd, basicQuality);<br />
- Set basic level of quality vs. required GPU performance.</p>
<p>oldSetting = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetFastResponse’, hmd [, enable]);<br />
- Return old setting for ‘FastResponse’ mode in ‘oldSetting’,<br />
optionally disable or enable the mode via specifying the ‘enable’<br />
parameter as 0 or greater than zero.</p>
<p>Currently not implemented / supported. Does nothing.</p>
<p>oldSetting = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetTimeWarp’, hmd [, enable]);<br />
- Return old setting for ‘TimeWarp’ mode in ‘oldSetting’, which is<br />
always 0 for ‘disabled’.<br />
Deprecated: Does nothing. Only for <a href="PsychVRHMD" class="uri">PsychVRHMD</a> compatibility.</p>
<p>oldSetting = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetLowPersistence’, hmd [, enable]);<br />
- Return old setting for ‘LowPersistence’ mode in ‘oldSetting’,<br />
optionally enable or disable the mode via specifying the ‘enable’<br />
parameter as 1 or 0.<br />
Currently not implemented / supported. Does nothing.</p>
<p><a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetHSWDisplayDismiss’, hmd [, dismissTypes=1+2]);<br />
- Set how the user can dismiss the “Health and safety warning display”.<br />
‘dismissTypes’ can be -1 to disable the HSWD, or a value &gt;= 0 to show<br />
the HSWD until a timeout and or until the user dismisses the HSWD.<br />
The following flags can be added to define type of dismissal:</p>
<p>+0 = Display until timeout, if any. Will wait forever if there isn’t any timeout!<br />
+1 = Dismiss via keyboard keypress.<br />
+2 = Dismiss via mouse click or mousepad tap.</p>
<p>[bufferSize, imagingFlags, stereoMode] = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetClientRenderingParameters’, hmd);<br />
- Retrieve recommended size in pixels ‘bufferSize’ = [width, height] of the client<br />
renderbuffer for each eye for rendering to the HMD. Returns parameters<br />
previously computed by <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘SetupRenderingParameters’, hmd).</p>
<p>Also returns ‘imagingFlags’, the required imaging mode flags for setup of<br />
the <a href="Screen" class="uri">Screen</a> imaging pipeline. Also returns the needed ‘stereoMode’ for the<br />
pipeline.</p>
<p>needPanelFitter = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetPanelFitterParameters’, hmd);<br />
- ‘needPanelFitter’ is 1 if a custom panel fitter tasks is needed, and ‘bufferSize’<br />
from the <a href="PsychVRHMD" class="uri">PsychVRHMD</a>(‘GetClientRenderingParameters’, hmd); defines the size of the<br />
clientRect for the onscreen window. ‘needPanelFitter’ is 0 if no panel fitter is<br />
needed.</p>
<p>[winRect, ovrfbOverrideRect, ovrSpecialFlags] = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘OpenWindowSetup’, hmd, screenid, winRect, ovrfbOverrideRect, ovrSpecialFlags);<br />
- Compute special override parameters for given input/output arguments, as needed<br />
for a specific HMD. Take other preparatory steps as needed, immediately before the<br />
<a href="Screen" class="uri">Screen</a>(‘OpenWindow’) command executes. This is called as part of <a href="PsychImaging" class="uri">PsychImaging</a>(‘OpenWindow’),<br />
with the user provided hmd, screenid, winRect etc.</p>
<p>isOutput = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘IsHMDOutput’, hmd, scanout);<br />
- Returns 1 (true) if ‘scanout’ describes the video output to which the<br />
HMD ‘hmd’ is connected. ‘scanout’ is a struct returned by the <a href="Screen" class="uri">Screen</a><br />
function <a href="Screen" class="uri">Screen</a>(‘ConfigureDisplay’, ‘Scanout’, screenid, outputid);<br />
This allows probing video outputs to find the one which feeds the HMD.</p>
<p>[headToEyeShiftv, headToEyeShiftMatrix] = <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetEyeShiftVector’, hmd, eye);<br />
- Retrieve 3D translation vector [tx, ty, tz] that defines the 3D position of the given<br />
eye ‘eye’ for the given HMD ‘hmd’, relative to the origin of the local head/HMD<br />
reference frame. This is needed to translate a global head pose into a eye<br />
pose, e.g., to translate the output of <a href="PsychOpenHMDVR" class="uri">PsychOpenHMDVR</a>(‘GetEyePose’) into actual<br />
tracked/predicted eye locations for stereo rendering.</p>
<p>In addition to the ‘headToEyeShiftv’ vector, a corresponding 4x4 translation<br />
matrix is also returned in ‘headToEyeShiftMatrix’ for convenience.</p>
<div class="code_header" style="text-align:right;">
<p><span style="float:left;">Path  </span> <span class="counter">Retrieve <a href=
  "https://raw.github.com/Psychtoolbox-3/Psychtoolbox-3/beta/Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOpenHMDVR.m">current version from GitHub</a> | View <a href=
  "https://github.com/Psychtoolbox-3/Psychtoolbox-3/commits/beta/Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOpenHMDVR.m">changelog</a></span></p>
</div>
<div class="code">
<p><code>Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOpenHMDVR.m</code></p>
</div>
