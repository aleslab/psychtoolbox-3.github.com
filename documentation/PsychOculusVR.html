<h2 id="psychtoolbox-psychhardware-psychvrtoolbox">[[Psychtoolbox]] › [[PsychHardware]] › [[PsychVRToolbox]]</h2>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a> - A high level driver for Oculus VR hardware.</p>
<p>Note: If you want to write VR code that is portable across<br />
VR headsets of different vendors, then use the <a href="PsychVRHMD" class="uri">PsychVRHMD</a>()<br />
driver instead of this driver. The <a href="PsychVRHMD" class="uri">PsychVRHMD</a> driver will use<br />
this driver as appropriate when connecting to a Oculus Rift<br />
or similar Oculus device, but it will also automaticaly work<br />
with other head mounted displays. This driver does however<br />
expose a few functions specific to Oculus hardware, so you can<br />
mix calls to this driver with calls to <a href="PsychVRHMD" class="uri">PsychVRHMD</a> to do some<br />
mix &amp; match.</p>
<p>For setup instructions for Oculus <a href="HMDs" class="uri">HMDs</a> see “help <a href="OculusVR" class="uri">OculusVR</a>”.</p>
<h3 id="usage">Usage:</h3>
<p>hmd = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘AutoSetupHMD’ [, basicTask=‘Tracked3DVR’][, basicRequirements][, basicQuality=0][, deviceIndex]);<br />
- Open a Oculus HMD, set it up with good default rendering and<br />
display parameters and generate a <a href="PsychImaging" class="uri">PsychImaging</a>(‘AddTask’, …)<br />
line to setup the Psychtoolbox imaging pipeline for proper display<br />
on the HMD. This will also cause the device connection to get<br />
auto-closed as soon as the onscreen window which displays on<br />
the HMD is closed. Returns the ‘hmd’ handle of the HMD on success.</p>
<p>By default, the first detected HMD will be used and if no VR HMD<br />
is connected, it will open an emulated/simulated one for basic<br />
testing and debugging. You can override this default choice of<br />
HMD by specifying the optional ‘deviceIndex’ parameter to choose<br />
a specific HMD.</p>
<p>More optional parameters: ‘basicTask’ what kind of task should be implemented.<br />
The default is ‘Tracked3DVR’, which means to setup for stereoscopic 3D<br />
rendering, driven by head motion tracking, for a fully immersive experience<br />
in some kind of 3D virtual world. This is the default if omitted. The task<br />
‘Stereoscopic’ sets up for display of stereoscopic stimuli, but without<br />
head tracking. ‘Monoscopic’ sets up for display of monocular stimuli, ie.<br />
the HMD is just used as a special kind of standard display monitor.</p>
<p>‘basicRequirements’ defines basic requirements for the task. Currently<br />
defined are the following strings which can be combined into a single<br />
‘basicRequirements’ string: ‘LowPersistence’ = Try to keep exposure<br />
time of visual images on the retina low if possible, ie., try to approximate<br />
a pulse-type display instead of a hold-type display if possible. This has<br />
no effect on the Rift DK1. On the Rift DK2 it will enable low persistence<br />
scanning of the OLED display panel, to light up each pixel only a fraction<br />
of a video refresh cycle duration.</p>
<p>‘PerEyeFOV’ = Request use of per eye individual and asymmetric fields of view even<br />
when the ‘basicTask’ was selected to be ‘Monoscopic’ or ‘Stereoscopic’. This allows<br />
for wider field of view in these tasks, but requires the usercode to adapt to these<br />
different and asymmetric fields of view for each eye, e.g., by selecting proper 3D<br />
projection matrices for each eye.</p>
<p>‘FastResponse’ = Try to switch images with minimal delay and fast<br />
pixel switching time. This will enable OLED panel overdrive processing<br />
on the Oculus Rift DK1 and DK2. OLED panel overdrive processing is a<br />
relatively expensive post processing step.</p>
<p>‘TimingSupport’ = Support some hardware specific means of timestamping<br />
or latency measurements. On the Rift DK1 this does nothing. On the DK2<br />
it enables dynamic prediction and timing measurements with the Rifts internal<br />
latency tester.</p>
<p>‘TimeWarp’ = Enable per eye image 2D timewarping via prediction of eye<br />
poses at scanout time. This mostly only makes sense for head-tracked 3D<br />
rendering. Depending on ‘basicQuality’ a more cheap or more expensive<br />
procedure is used.</p>
<p>‘basicQuality’ defines the basic tradeoff between quality and required<br />
computational power. A setting of 0 gives lowest quality, but with the<br />
lowest performance requirements. A setting of 1 gives maximum quality at<br />
maximum computational load. Values between 0 and 1 change the quality to<br />
performance tradeoff.</p>
<p>hmd = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘Open’ [, deviceIndex], …);<br />
- Open HMD with index ‘deviceIndex’. See <a href="PsychOculusVRCore" class="uri">PsychOculusVRCore</a> Open?<br />
for help on additional parameters.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetAutoClose’, hmd, mode);<br />
- Set autoclose mode for HMD with handle ‘hmd’. ‘mode’ can be<br />
0 (this is the default) to not do anything special. 1 will close<br />
the HMD ‘hmd’ when the onscreen window is closed which displays<br />
on the HMD. 2 will do the same as 1, but close all open <a href="HMDs" class="uri">HMDs</a> and<br />
shutdown the complete driver and Oculus runtime - a full cleanup.</p>
<p>isOpen = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘IsOpen’, hmd);<br />
- Returns 1 if ‘hmd’ corresponds to an open HMD, 0 otherwise.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘<a href="Close" class="uri">Close</a>’ [, hmd])<br />
- <a href="Close" class="uri">Close</a> provided HMD device ‘hmd’. If no ‘hmd’ handle is provided,<br />
all <a href="HMDs" class="uri">HMDs</a> will be closed and the driver will be shutdown.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘Controllers’, hmd);<br />
- Return a bitmask of all connected controllers: Can be the bitand<br />
of the OVR.<a href="ControllerType" class="uri">ControllerType</a>_XXX flags described in ‘GetInputState’.<br />
This does not detect if controllers are hot-plugged or unplugged after<br />
the HMD was opened. Iow. only probed at ‘Open’.<br />
As the classic Oculus driver does not support dedicated controllers at the<br />
moment, this always returns 0.</p>
<p>info = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetInfo’, hmd);<br />
- Retrieve a struct ‘info’ with information about the HMD ‘hmd’.<br />
The returned info struct contains at least the following standardized<br />
fields with information:<br />
handle = Driver internal handle for the specific HMD.<br />
driver = Function handle to the actual driver for the HMD, e.g., @<a href="PsychOculusVR" class="uri">PsychOculusVR</a>.<br />
type = Defines the type/vendor of the device, e.g., ‘Oculus’.<br />
modelName = Name string with the name of the model of the device, e.g., ‘Rift DK2’.<br />
separateEyePosesSupported = 1 if use of <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetEyePose’) will improve<br />
the quality of the VR experience, 0 if no improvement<br />
is to be expected, so ‘GetEyePose’ can be avoided<br />
to save processing time without a loss of quality.<br />
This always returns 1 for at least the Rift DK1 and DK2,<br />
as use of that function can enhance the quality of the<br />
VR experience with fast head movements.</p>
<p>The returned struct may contain more information, but the fields mentioned<br />
above are the only ones guaranteed to be available over the long run. Other<br />
fields may disappear or change their format and meaning anytime without<br />
warning.</p>
<p>isSupported = <a href="PsychOculusVRCore" class="uri">PsychOculusVRCore</a>(‘Supported’);<br />
- Returns 1 if the Oculus driver is functional, 0 otherwise. The<br />
driver is functional if the VR runtime library was successfully<br />
initialized and a connection to the VR server process has been<br />
established. It would return 0 if the server process would not be<br />
running, or if the required runtime library would not be correctly<br />
installed.</p>
<p>[isVisible, playAreaBounds, <a href="OuterAreaBounds" class="uri">OuterAreaBounds</a>] = <a href="PsychOculusVRCore" class="uri">PsychOculusVRCore</a>(‘VRAreaBoundary’, hmd [, requestVisible]);<br />
- Request visualization of the VR play area boundary for ‘hmd’ and returns its<br />
current extents.</p>
<p>As VR area boundaries are not actually supported by this Oculus classic driver,<br />
this function returns no-op results, compatible with what the new Oculus driver<br />
would return if the Oculus guardian system would not be set up, e.g., because the<br />
hardware setup does not include Oculus touch controllers.</p>
<p>The input flag ‘requestVisible’ is silently ignored:<br />
‘requestVisible’ 1 = Request showing the boundary area markers, 0 = Don’t<br />
request showing the markers.</p>
<p>Returns in ‘isVisible’ the current visibility status of the VR area boundaries.<br />
This is always 0 for “invisible”.</p>
<p>‘playAreaBounds’ is an empty matrix defining the play area boundaries. The empty<br />
return argument means that the play area is so far undefined on this driver.</p>
<p>‘OuterAreaBounds’ defines the outer area boundaries in the same way as<br />
‘playAreaBounds’. In other words, it always returns an empty matrix.</p>
<p>input = <a href="PsychOculusVRCore" class="uri">PsychOculusVRCore</a>(‘GetInputState’, hmd, controllerType);<br />
- Get input state of controller ‘controllerType’ associated with HMD ‘hmd’.</p>
<p>As this driver does not actually support special VR controllers, only a minimally<br />
useful ‘input’ state is returned for compatibility with other drivers, which is<br />
based on emulating or faking input from real controllers, so this function will be<br />
of limited use. Specifically, only the input.Time and input.Buttons fields are<br />
returned, all other fields are missing. input.Buttons maps defined OVR.Button_XXX<br />
fields to similar or corresponding buttons on the regular keyboard.</p>
<p>‘controllerType’ can be one of OVR.<a href="ControllerType" class="uri">ControllerType</a>_LTouch, OVR.<a href="ControllerType" class="uri">ControllerType</a>_RTouch,<br />
OVR.<a href="ControllerType" class="uri">ControllerType</a>_Touch, OVR.<a href="ControllerType" class="uri">ControllerType</a>_Remote, OVR.<a href="ControllerType" class="uri">ControllerType</a>_XBox, or<br />
OVR.<a href="ControllerType" class="uri">ControllerType</a>_Active for selecting whatever controller is currently active.</p>
<p>Return argument ‘input’ is a struct with fields describing the state of buttons and<br />
other input elements of the specified ‘controllerType’. It has the following fields:</p>
<p>‘Time’ Time of last input state change of controller.<br />
‘Buttons’ Vector with button state on the controller, similar to the ‘keyCode’<br />
vector returned by <a href="KbCheck" class="uri">KbCheck</a>() for regular keyboards. Each position in the vector<br />
reports pressed (1) or released (0) state of a specific button. Use the OVR.Button_XXX<br />
constants to map buttons to positions.</p>
<p>pulseEndTime = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘HapticPulse’, hmd, controllerType [, duration=2.5][, freq=1.0][, amplitude=1.0]);<br />
- Fake triggering a haptic feedback pulse. This does nothing, but return a made up<br />
but consistent ‘pulseEndTime’, as this classic Oculus driver does not support haptic<br />
feedback.</p>
<p>state = <a href="PsychOculusVRCore" class="uri">PsychOculusVRCore</a>(‘PrepareRender’, hmd [, userTransformMatrix][, reqmask=1][, targetTime]);<br />
- Mark the start of the rendering cycle for a new 3D rendered stereoframe.<br />
Return a struct ‘state’ which contains various useful bits of information<br />
for 3D stereoscopic rendering of a scene, based on head tracking data.</p>
<p>‘hmd’ is the handle of the HMD which delivers tracking data and receives the<br />
rendered content for display.</p>
<p>‘reqmask’ defines what kind of information is requested to be returned in<br />
struct ‘state’. Only query information you actually need, as computing some<br />
of this info is expensive! See below for supported values for ‘reqmask’.</p>
<p>‘targetTime’ is the expected time at which the rendered frame will display.<br />
This could potentially be used by the driver to make better predictions of<br />
camera/eye/head pose for the image. Omitting the value will use a target time<br />
that is implementation specific, but known to give generally good results,<br />
e.g., the midpoint of scanout of the next video frame.</p>
<p>‘userTransformMatrix’ is an optional 4x4 right hand side (RHS) transformation<br />
matrix. It gets applied to the tracked head pose as a global transformation<br />
before computing results based on head pose like, e.g., camera transformations.<br />
You can use this to translate the “virtual head” and thereby the virtual eyes/<br />
cameras in the 3D scene, so observer motion is not restricted to the real world<br />
tracking volume of your headset. A typical ‘userTransformMatrix’ would be a<br />
combined translation and rotation matrix to position the observer at some<br />
3D location in space, then define his/her global looking direction, aka as<br />
heading angle, yaw orientation, or rotation around the y-axis in 3D space.<br />
Head pose tracking results would then operate relative to this global transform.<br />
If ‘userTransformMatrix’ is left out, it will default to an identity transform,<br />
in other words, it will do nothing.</p>
<p>state always contains a field state.tracked, whose bits signal the status<br />
of head tracking for this frame. A +1 flag means that head orientation is<br />
tracked. A +2 flag means that head position is tracked via some absolute<br />
position tracker like, e.g., the Oculus Rift DK2 camera.</p>
<p>state always contains a field state.tracked, whose bits signal the status<br />
of head tracking for this frame. A +1 flag means that head orientation is<br />
tracked. A +2 flag means that head position is tracked via some absolute<br />
position tracker like, e.g., the Oculus Rift DK2 camera. We also return a +128<br />
flag which means the HMD is actually strapped onto the subjects head and displaying<br />
our visual content. We can’t detect actual HMD display state, but do this for<br />
compatibility to other drivers.</p>
<p>state also always contains a field state.<a href="SessionState" class="uri">SessionState</a>, whose bits signal general<br />
VR session status. In our case we always return +7 on this classic Oculus driver,<br />
as we can’t detect <a href="ShouldQuit" class="uri">ShouldQuit</a>, <a href="ShouldRecenter" class="uri">ShouldRecenter</a> or <a href="DisplayLost" class="uri">DisplayLost</a> conditions, neither<br />
if the HMD is strapped to the users head.</p>
<p>+1 = Our rendering goes to the HMD, ie. we have control over it. Lack of this could<br />
mean the Health and Safety warning is displaying at the moment and waiting for<br />
acknowledgement, or the Oculus GUI application is in control.<br />
+2 = HMD is present and active.<br />
+4 = HMD is strapped onto users head. E.g., a Oculus Rift CV1 would switch off/blank<br />
if not on the head.<br />
+8 = <a href="DisplayLost" class="uri">DisplayLost</a> condition! Some hardware/software malfunction, need to completely quit this<br />
Psychtoolbox session to recover from this.<br />
+16 = <a href="ShouldQuit" class="uri">ShouldQuit</a> The user interface / user asks us to voluntarily terminate this session.<br />
+32 = <a href="ShouldRecenter" class="uri">ShouldRecenter</a> = The user interface asks us to recenter/recalibrate our tracking origin.</p>
<h3 id="reqmask-defaults-to-1-and-can-have-the-following-values-added-together">‘reqmask’ defaults to 1 and can have the following values added together:</h3>
<p>+1 = Return matrices for left and right “eye cameras” which can be directly<br />
used as <a href="OpenGL" class="uri">OpenGL</a> GL_MODELVIEW matrices for rendering the scene. 4x4 matrices<br />
for left- and right eye are contained in state.modelView{1} and {2}.</p>
<pre><code> Return position and orientation 4x4 camera view matrices which describe  
 position and orientation of the &quot;eye cameras&quot; relative to the world  
 reference frame. They are the inverses of state.modelView{}. These  
 matrices can be directly used to define cameras for rendering of complex  
 3D scenes with the [Horde3D](Horde3D) 3D engine. Left- and right eye matrices are  
 contained in state.cameraView{1} and {2}.  

 Additionally tracked/predicted head pose is returned in state.localHeadPoseMatrix  
 and the global head pose after application of the &#39;userTransformMatrix&#39; is  
 returned in state.globalHeadPoseMatrix - this is the basis for computing  
 the camera transformation matrices.  </code></pre>
<p>+2 = Return matrices for tracked left and right hands of user, ie. of tracked positions<br />
and orientations of left and right hand tracking controllers, if any. As the old<br />
driver does not support hand tracking, this reports hard-coded neutral results and<br />
reports a state.handStatus of 0 = “Not tracked/Invalid data”.</p>
<pre><code> state.handStatus(1) = Tracking status of left hand: 0 = Untracked, signalling that  
                       all the following information is invalid and can not be used  
                       in any meaningful way.  

 state.handStatus(2) = Tracking status of right hand. 0 = Untracked.  

 state.localHandPoseMatrix{1} = 4x4 [OpenGL](OpenGL) right handed reference frame matrix with  
                                hand position and orientation encoded to define a  
                                proper GL\_MODELVIEW transform for rendering stuff  
                                &quot;into&quot;/&quot;relative to&quot; the oriented left hand. Always  
                                a 4x4 unit identity matrix for hand resting in origin.  

 state.localHandPoseMatrix{2} = Ditto for the right hand.  

 state.globalHandPoseMatrix{1} = userTransformMatrix \* state.localHandPoseMatrix{1};  
                                 Left hand pose transformed by passed in userTransformMatrix.  

 state.globalHandPoseMatrix{2} = Ditto for the right hand.  

 state.globalHandPoseInverseMatrix{1} = Inverse of globalHandPoseMatrix{1} for collision  
                                        testing/grasping of virtual objects relative to  
                                        hand pose of left hand.  

 state.globalHandPoseInverseMatrix{2} = Ditto for right hand.  </code></pre>
<p>More flags to follow…</p>
<p>eyePose = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetEyePose’, hmd, renderPass [, userTransformMatrix][, targetTime]);<br />
- Return a struct ‘eyePose’ which contains various useful bits of information<br />
for 3D stereoscopic rendering of the stereo view of one eye, based on head<br />
tracking data. This function provides essentially the same information as<br />
the ‘PrepareRender’ function, but only for one eye. Therefore you will need<br />
to call this function twice, once for each of the two renderpasses, at the<br />
beginning of each renderpass.</p>
<p>‘hmd’ is the handle of the HMD which delivers tracking data and receives the<br />
rendered content for display.</p>
<p>‘renderPass’ defines if information should be returned for the 1st renderpass<br />
(renderPass == 0) or for the 2nd renderpass (renderPass == 1). The driver will<br />
decide for you if the 1st renderpass should render the left eye and the 2nd<br />
pass the right eye, or if the 1st renderpass should render the right eye and<br />
then the 2nd renderpass the left eye. The ordering depends on the properties<br />
of the video display of your HMD, specifically on the video scanout order:<br />
Is it right to left, left to right, or top to bottom? For each scanout order<br />
there is an optimal order for the renderpasses to minimize perceived lag.</p>
<p>‘targetTime’ is the expected time at which the rendered frame will display.<br />
This could potentially be used by the driver to make better predictions of<br />
camera/eye/head pose for the image. Omitting the value will use a target time<br />
that is implementation specific, but known to give generally good results.</p>
<p>‘userTransformMatrix’ is an optional 4x4 right hand side (RHS) transformation<br />
matrix. It gets applied to the tracked head pose as a global transformation<br />
before computing results based on head pose like, e.g., camera transformations.<br />
You can use this to translate the “virtual head” and thereby the virtual eyes/<br />
cameras in the 3D scene, so observer motion is not restricted to the real world<br />
tracking volume of your headset. A typical ‘userTransformMatrix’ would be a<br />
combined translation and rotation matrix to position the observer at some<br />
3D location in space, then define his/her global looking direction, aka as<br />
heading angle, yaw orientation, or rotation around the y-axis in 3D space.<br />
Head pose tracking results would then operate relative to this global transform.<br />
If ‘userTransformMatrix’ is left out, it will default to an identity transform,<br />
in other words, it will do nothing.</p>
<h3 id="return-values-in-struct-eyepose">Return values in struct ‘eyePose’:</h3>
<p>‘eyeIndex’ The eye for which this information applies. 0 = Left eye, 1 = Right eye.<br />
You can pass ‘eyeIndex’ into the <a href="Screen" class="uri">Screen</a>(‘SelectStereoDrawBuffer’, win, eyeIndex)<br />
to select the proper eye target render buffer.</p>
<p>‘modelView’ is a 4x4 RHS <a href="OpenGL" class="uri">OpenGL</a> matrix which can be directly used as <a href="OpenGL" class="uri">OpenGL</a><br />
GL_MODELVIEW matrix for rendering the scene.</p>
<p>‘cameraView’ contains a 4x4 RHS camera matrix which describes position and<br />
orientation of the “eye camera” relative to the world reference<br />
frame. It is the inverse of eyePose.modelView. This matrix can<br />
be directly used to define the camera for rendering of complex<br />
3D scenes with the <a href="Horde3D" class="uri">Horde3D</a> 3D engine or other engines which want<br />
absolute camera pose instead of the inverse matrix.</p>
<p>Additionally tracked/predicted head pose is returned in eyePose.localHeadPoseMatrix<br />
and the global head pose after application of the ‘userTransformMatrix’ is<br />
returned in eyePose.globalHeadPoseMatrix - this is the basis for computing<br />
the camera transformation matrix.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetupRenderingParameters’, hmd [, basicTask=‘Tracked3DVR’][, basicRequirements][, basicQuality=0][, fov=[<a href="HMDRecommended" class="uri">HMDRecommended</a>]][, pixelsPerDisplay=1])<br />
- Query the HMD ‘hmd’ for its properties and setup internal rendering<br />
parameters in preparation for opening an onscreen window with <a href="PsychImaging" class="uri">PsychImaging</a><br />
to display properly on the HMD. See section about ‘AutoSetupHMD’ above for<br />
the meaning of the optional parameters ‘basicTask’, ‘basicRequirements’<br />
and ‘basicQuality’.</p>
<p>‘fov’ Optional field of view in degrees, from line of sight: [leftdeg, rightdeg,<br />
updeg, downdeg]. If ‘fov’ is omitted, the HMD runtime will be asked for a<br />
good default field of view and that will be used. The field of view may be<br />
dependent on the settings in the HMD user profile of the currently selected<br />
user.</p>
<p>‘pixelsPerDisplay’ Ratio of the number of render target pixels to display pixels<br />
at the center of distortion. Defaults to 1.0 if omitted. Lower values can<br />
improve performance, at lower quality.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetBasicQuality’, hmd, basicQuality);<br />
- Set basic level of quality vs. required GPU performance.</p>
<p>oldSetting = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetFastResponse’, hmd [, enable]);<br />
- Return old setting for ‘FastResponse’ mode in ‘oldSetting’,<br />
optionally disable or enable the mode via specifying the ‘enable’<br />
parameter as 0 or greater than zero. Please note that if you want to<br />
use ‘FastResponse’, you must request and thereby enable it at the<br />
beginning of a session, as the driver must do some neccessary setup<br />
prep work at startup of the HMD. Once it was initially enabled, you<br />
can switch the setting at runtime with this function.</p>
<p>Currently implemented are an algorithmic overdrive mode if ‘enable’<br />
is set to 1, and two lookup table (LUT) based modes for ‘enable’<br />
settings of 2 or 3, each selecting a slightly different lookup table.</p>
<p>oldSetting = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetTimeWarp’, hmd [, enable]);<br />
- Return old setting for ‘TimeWarp’ mode in ‘oldSetting’,<br />
optionally enable or disable the mode via specifying the ‘enable’<br />
parameter as 1 or 0. Please note that if you want to use ‘TimeWarp’,<br />
you must request and thereby enable it at the beginning of a session, as<br />
the driver must do some neccessary setup prep work at startup of the HMD.<br />
Once it was initially enabled, you can switch the setting at runtime with<br />
this function.</p>
<p>oldSetting = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetLowPersistence’, hmd [, enable]);<br />
- Return old setting for ‘LowPersistence’ mode in ‘oldSetting’,<br />
optionally enable or disable the mode via specifying the ‘enable’<br />
parameter as 1 or 0.</p>
<p>oldSettings = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘PanelOverdriveParameters’, hmd [, newparams]);<br />
- Return old settings for panel overdrive mode in ‘oldSettings’,<br />
optionally set new settings in ‘newparams’. This changes the operating<br />
parameters of OLED panel overdrive on the Rift DK-2 if ‘FastResponse’<br />
mode is active. newparams is a vector [upscale, downscale, gamma] with<br />
the following meaning: gamma = 1 Use gamma/degamma pass to perform<br />
overdrive boost in gamma 2.2 corrected space. This is the startup default.<br />
upscale = How much should rising pixel color intensity values be boosted.<br />
Default is 0.10 for a 10% boost.<br />
downscale = How much should rising pixel color intensity values be reduced.<br />
Default is 0.05 for a 5% reduction.<br />
The Rift DK-2 OLED panel controller is slower on rising intensities than on<br />
falling intensities, therefore the higher boost on rising than on falling<br />
direction.</p>
<p><a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetHSWDisplayDismiss’, hmd [, dismissTypes=1+2+4]);<br />
- Set how the user can dismiss the “Health and safety warning display”.<br />
‘dismissTypes’ can be -1 to disable the HSWD, or a value &gt;= 0 to show<br />
the HSWD until a timeout and or until the user dismisses the HSWD.<br />
The following flags can be added to define type of dismissal:</p>
<p>+0 = Display until timeout, if any. Will wait forever if there isn’t any timeout!<br />
+1 = Dismiss via keyboard keypress.<br />
+2 = Dismiss via mouse click or mousepad tap.<br />
+4 = Dismiss via a tap to the HMD (detected via accelerometer).</p>
<p>[bufferSize, imagingFlags, stereoMode] = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetClientRenderingParameters’, hmd);<br />
- Retrieve recommended size in pixels ‘bufferSize’ = [width, height] of the client<br />
renderbuffer for each eye for rendering to the HMD. Returns parameters<br />
previously computed by <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘SetupRenderingParameters’, hmd).</p>
<p>Also returns ‘imagingFlags’, the required imaging mode flags for setup of<br />
the <a href="Screen" class="uri">Screen</a> imaging pipeline. Also returns the needed ‘stereoMode’ for the<br />
pipeline.</p>
<p>needPanelFitter = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetPanelFitterParameters’, hmd);<br />
- ‘needPanelFitter’ is 1 if a custom panel fitter tasks is needed, and ‘bufferSize’<br />
from the <a href="PsychVRHMD" class="uri">PsychVRHMD</a>(‘GetClientRenderingParameters’, hmd); defines the size of the<br />
clientRect for the onscreen window. ‘needPanelFitter’ is 0 if no panel fitter is<br />
needed.</p>
<p>[winRect, ovrfbOverrideRect, ovrSpecialFlags] = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘OpenWindowSetup’, hmd, screenid, winRect, ovrfbOverrideRect, ovrSpecialFlags);<br />
- Compute special override parameters for given input/output arguments, as needed<br />
for a specific HMD. Take other preparatory steps as needed, immediately before the<br />
<a href="Screen" class="uri">Screen</a>(‘OpenWindow’) command executes. This is called as part of <a href="PsychImaging" class="uri">PsychImaging</a>(‘OpenWindow’),<br />
with the user provided hmd, screenid, winRect etc.</p>
<p>isOutput = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘IsHMDOutput’, hmd, scanout);<br />
- Returns 1 (true) if ‘scanout’ describes the video output to which the<br />
HMD ‘hmd’ is connected. ‘scanout’ is a struct returned by the <a href="Screen" class="uri">Screen</a><br />
function <a href="Screen" class="uri">Screen</a>(‘ConfigureDisplay’, ‘Scanout’, screenid, outputid);<br />
This allows probing video outputs to find the one which feeds the HMD.</p>
<p>[headToEyeShiftv, headToEyeShiftMatrix] = <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetEyeShiftVector’, hmd, eye);<br />
- Retrieve 3D translation vector [tx, ty, tz] that defines the 3D position of the given<br />
eye ‘eye’ for the given HMD ‘hmd’, relative to the origin of the local head/HMD<br />
reference frame. This is needed to translate a global head pose into a eye<br />
pose, e.g., to translate the output of <a href="PsychOculusVR" class="uri">PsychOculusVR</a>(‘GetEyePose’) into actual<br />
tracked/predicted eye locations for stereo rendering.</p>
<p>In addition to the ‘headToEyeShiftv’ vector, a corresponding 4x4 translation<br />
matrix is also returned in ‘headToEyeShiftMatrix’ for convenience.</p>
<div class="code_header" style="text-align:right;">
<p><span style="float:left;">Path  </span> <span class="counter">Retrieve <a href=
  "https://raw.github.com/Psychtoolbox-3/Psychtoolbox-3/beta/Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOculusVR.m">current version from GitHub</a> | View <a href=
  "https://github.com/Psychtoolbox-3/Psychtoolbox-3/commits/beta/Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOculusVR.m">changelog</a></span></p>
</div>
<div class="code">
<p><code>Psychtoolbox/PsychHardware/PsychVRToolbox/PsychOculusVR.m</code></p>
</div>
