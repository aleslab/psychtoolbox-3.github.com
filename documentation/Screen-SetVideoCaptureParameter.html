<h1 id="screensetvideocaptureparameter"><a href="Screen-SetVideoCaptureParameter">Screen(‘SetVideoCaptureParameter’)</a></h1>
<h2 id="psychtoolbox-screen.mexdll-subfunction">[[Psychtoolbox]] › [[Screen]].{mex*,dll} subfunction</h2>
<p>Set video capture parameter ‘parameterName’ on video capture device<br />
‘capturePtr’.<br />
If ‘value’ is provided, then the parameter is set to ‘value’ and the parameter<br />
is switched to manual control mode. If ‘value’ is left out, then the current<br />
setting of ‘parameterName’ is queried and returned. If ‘parameterName’ starts<br />
with the word ‘Auto’ then the parameter is switched to automatic control, if<br />
supported. In any case, the old value is returned. Type and range of supported<br />
capture parameters varies between different capture devices and operating<br />
systems. Your specific device may only support a subset (or none) of the<br />
available parameters. If you specify an unsupported ‘parameterName’, your<br />
request will be silently ignored, except that the return value is set to DBL_MAX<br />
- a very high number. The following settings are currently available on devices<br />
that support them: ‘Brightness’, ‘Gain’, ‘Exposure’, ‘Shutter’, ‘Sharpness’,<br />
‘Hue’, ‘Saturation’, ‘Gamma’, ‘Iris’, ‘Focus’, ‘Zoom’, ‘Pan’, ‘Tilt’,<br />
‘OpticalFilter’, ‘CaptureSize’, ‘CaptureQuality’, ‘FrameRate’, ‘TriggerDelay’.<br />
The special setting ‘PrintParameters’ prints all features to the command window.<br />
‘GetVendorname’ and ‘GetModelname’ return the name of the device vendor, resp.<br />
the device model name. ‘GetROI’ returns the capture region of interest (ROI),<br />
which can deviate from the ROI requested in <a href="Screen" class="uri">Screen</a>(‘OpenVideoCapture’),<br />
depending on the capabilities of the capture device. ‘SetNextCaptureBinSpec=xxx’<br />
Will set the gst-launch line which describes the video capture source to be used<br />
during the next call to <a href="Screen" class="uri">Screen</a>(‘OpenVideoCapture’, -9, …); Opening a video<br />
capture device with the special deviceIndex -9 means to create a [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) bin<br />
and use it as video source. The bin is created by parsing the string passed<br />
here. Use the special ‘capturePtr’ value -1 when setting this bin description,<br />
as this call may need to be made while a capture device is not yet opened, so no<br />
valid ‘capturePtr’ exists. This setting is only honored on the [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) video<br />
capture engine.<br />
‘GetFramerate’ Returns the nominal capture rate of the capture device.<br />
‘GetBandwidthUsage’ Returns firewire bandwidth used by camera at current<br />
settings in so called bandwidth units. The 1394 bus has 4915 bandwidth units<br />
available per cycle. Each unit corresponds to the time it takes to send one<br />
quadlet at ISO speed S1600. The bandwidth usage at S400 is thus four times the<br />
number of quadlets per packet. In other words, it is complicated. This returns<br />
normalized bus bandwidth usage between 0.0 for 0% and 1.0 for 100%, assuming<br />
4915 units correspond to 100% bus utilization.<br />
‘SetNewMoviename=xxx’ Will change the name of the videofile used for video<br />
recording to xxx. This allows you to change target files for video recordings<br />
without the need to close and reopen the capture device. You must stop capture<br />
though and then restart it after assigning a new filename.<br />
‘SetGStreamerProcessingPipeline=xxx’ This assigns a [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) gst-launch style<br />
pipeline for use during post-processing of captured video on a libdc1394 capture<br />
device. This is only supported if multi-threaded video capture or recording is<br />
active via recordingflags &amp; 16 and video capture was started with the<br />
‘dropframes’ = 0 setting, so that all captured video is processed by a realtime<br />
thread and pushed through a [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) processing pipeline. You can build a<br />
processing pipeline of standard [<a href="GStreamer" class="uri">GStreamer</a>][(GStreamer)]((GStreamer)) plugins to do something to the video<br />
frames after they’ve been captured but before they are returned via<br />
<a href="Screen" class="uri">Screen</a>(‘GetCapturedImage’). The processing does not have any effect on recorded<br />
video footage.<br />
‘StopAtFramecount’ Set or retrieve the framecounter value at which the camera<br />
should stop its capture operation. By default the camera will empty its queue of<br />
captured images before stopping in free-running mode. In synchronized mode it<br />
will stop at the same framecounter value as the master camera, so all cams<br />
capture the same number of frames. You can override these defaults and specify<br />
an arbitrary value with this setting. However, be careful in synchronized mode<br />
to not specify a target stop count which can’t be reached by a slave camera once<br />
capture stops synchronously on all cameras, otherwise stopping that camera will<br />
be impossible and result in a hard hang of your script!<br />
‘GetCorruptFramecount’ Retrieve current count of corrupted frames received from<br />
a camera. Not all cameras and operating systems can detect and report corrupt<br />
frames. Currently only implemented on libdc1394 capture engine.<br />
‘GetCurrentFramecount’ Retrieve current count of captured frames on a camera.<br />
‘GetFutureMaxFramecount’ Retrieve current maximum count which could be reached<br />
if you’d try to stop capture right now.<br />
‘GetFetchedFramecount’ Retrieve framecount of last frame fetched via<br />
<a href="Screen" class="uri">Screen</a>(‘GetCapturedImage’). This is the running counter value at the time the<br />
video frame was captured, essentially a copy of ‘GetCurrentFramecount’ stamped<br />
onto the retrieved video frame.<br />
‘PreferFormat7Modes’ If set to 1, prefer Format-7 video capture modes over other<br />
modes, even if given capture settings for fps and resolution and ROI would allow<br />
otherwise. Format-7 modes are only supported by more high-end cams, but using<br />
them sometimes allows to save bus-bandwidth in addition to the higher<br />
flexibility. If you find yourself starving for bandwidth it may be worth a try<br />
to set this preference. The default setting 0 will use non-Format-7 by default<br />
and only choose Format-7 if this is needed to satisfy given ROI, framerate and<br />
resolution settings.<br />
‘DataConversionMode’ What kind of image data should be requested from the camera<br />
and how should it be postprocessed? This controls the tradeoff between required<br />
bus-bandwidth on Firewire/USB busses and processing load on the cpu or gpu of<br />
the host computer, allowing to prioritize one over the other. Possible settings:<br />
0 = Don’t care (Default setting), 1 = Request raw data and return it<br />
unprocessed. 2 = Request raw data but post-process it into a standard format<br />
(Luminance for 1 layer, RGB for 3 layer images), 3 = Request mono/rgb filtered<br />
data from camera and return it unprocessed (as processing should not be needed),<br />
4 = Request mono data but post-process it as if it were raw data (convert to<br />
mono or rgb). Option 1 minimizes bus bandwidth, memory consumption and cpu load<br />
but requires manual post processing by you at some time. Option 2 minimizes bus<br />
bandwidth but not memory consumption and it significantly increases cpu load.<br />
Option 3 minimizes cpu load but maximizes bus bandwidth consumption. The default<br />
option 0 will do whatever is convenient for the attached camera. Option 1 only<br />
makes sense if you request 1 layer data. Option 4 is like option 2, but for<br />
broken cameras which deliver raw data in mono format instead of the<br />
spec-compliant raw format. Option 3 in combination with 1 layer image format can<br />
be used to get raw data from broken cameras which deliver raw data mislabeled as<br />
mono data.<br />
‘DebayerMethod’ Select method of bayer filtering for conversion of raw sensor<br />
data to RGB images. Different methods represent different tradeoffs between<br />
quality and computation time. Method 0 (the Default) is the fastest and lowest<br />
quality method, whereas higher numbers select higher quality and more cpu load.<br />
Currently values 0 to 7 may be valid for your system. This can be also used with<br />
a ‘capturePtr’ of -1 to set the method used during movie playback.<br />
‘OverrideBayerPattern’ If you choose color image output from raw sensor input,<br />
via one of the ‘DataConversionMode’ settings, then a bayer filter operation must<br />
be performed to convert raw sensor data to RGB data. The filter operation must<br />
know the bayer filter layout of your cameras sensor, but this layout can’t get<br />
auto-detected on all cameras in all modes of operation. If the bayer conversion<br />
aborts due to this, you may need to manually specify the bayer filter pattern to<br />
use with the ‘OverrideBayerPattern’ setting: 0 = RGGB, 1 = GBRG, 2 = GRBG, 3 =<br />
BGGR. This can be also used with a ‘capturePtr’ of -1 to set the method used<br />
during movie playback.<br />
‘SyncMode’ Query or set mode flags for synchronization of the video capture<br />
operation of multiple cameras. This setting is currently only supported with the<br />
dedicated libdc1394 video capture engine (engine id 1), and only for some types<br />
of cameras on some operating systems, specifically as of Nov 2013 it only works<br />
on Linux with firewire cameras. The default setting for ‘SyncMode’ is zero,<br />
which means the camera is free-running, independent of any other camera.<br />
Non-zero values allow to synchronize the capture operation of the camera with<br />
other cameras. Each camera can be either a sync-master, which means it controls<br />
all capture operations (start, stop and timing of capture), or a sync-slave,<br />
which means its timing is controlled by the master camera. There can be at most<br />
one master for synchronized operation. If hardware sync is selected and an<br />
external trigger signal source is used, no master camera is needed. For the<br />
master camera, set the ‘SyncMode’ to 1, for a slave camera set it to 2. There<br />
are three different sync strategies. Select exactly one by adding the value 4, 8<br />
or 16 to the ‘SyncMode’ value of 1 or 2, e.g., 1+4 to select soft-sync mode and<br />
define a soft-sync master:<br />
4 = Soft-Sync: Synchronisation happens purely in software. Works always but less<br />
accurate!<br />
8 = Bus-Sync: All cameras on a given firewire bus are synchronized down to ~125<br />
usecs. This only works with some cameras which support bus-sync, and usually<br />
only if they are identical camera models with identical settings. Also it only<br />
works for cameras on the same firewire bus, e.g., multiple cams connected to the<br />
same port on the computer via a common firewire hub or via daisy-chaining. Bus<br />
sync is elegant if it works, with no need for extra cabling and electronics.<br />
16 = Hw-Sync: All slave cameras are connected via some dedicated trigger signal<br />
distribution cables to a master camera or to an external trigger signal source.<br />
The master camera or external source drives capture operations and timing of all<br />
connected slave cameras. This is most reliable and accurate, but requires extra<br />
cabling and hardware. If you use this option, also use the trigger configuration<br />
commmands below to configure each camera individually as a master or slave, the<br />
trigger source port, and the type and polarity of the external trigger signal to<br />
use.<br />
In any case, for synchronized operation you must always first start capture on<br />
all participating slave cameras, then finally on the designated master - which<br />
will actually truly start capture of the whole pack. For stopping capture you<br />
first stop the master, which will actually stop capture of the whole setup, then<br />
all slaves to disengage them. If you need cameras to start and perform capture<br />
and recording in sync, but you don’t need them to stop in exact synchrony, you<br />
can add the flag 32 = No lock-step. This allows for some slack and inaccuracy in<br />
stopping capture and recording, but may allow for reduced latency for realtime<br />
applications of video capture.<br />
The way trigger signals are used if ‘SyncMode’ is selected as mode 16 aka<br />
hardware sync, can be controlled via the following settings:<br />
‘TriggerMode’ The way a trigger signal controls camera capture operation: 0 =<br />
Start of exposure is triggered by falling edge of trigger signal, duration of<br />
exposure is controlled by shutter setting. 1 = Exposure starts with falling edge<br />
and stops with rising edge. Modes 2, 3, 4 and 5 are multiple exposure modes.<br />
Modes 6 and 7 are vendor specific modes.<br />
‘TriggerPolarity’ 0 = Active low / falling edge. 1 = Active high / rising edge =<br />
Inverted polarity.<br />
‘TriggerSource’ Which source input port to use: Sources 0 to 3 are available,<br />
corresponding to ports 0 - 3.<br />
‘GetTriggerSources’ Returns a list of supported source ports for given camera.<br />
‘PIO’ Set or get general purpose programmable IO pins on camera. Accepts/returns<br />
a 32-Bit integer value to control up to 32 pins. The value is provided and<br />
expected as a double, ie. a uint32 cast from/to a double.<br />
‘1394BModeActive’ Set or get if Firewire-800 mode aka 1394B mode is active: 1 =<br />
Activate, 0 = Use default classic mode.<br />
‘ISOSpeed’ Get/Set Firewire ISO bus speed: Valid values are 100, 200, 400, 800,<br />
1600, 3200 <a href="MBit" class="uri">MBit</a>/s. Default is 400 <a href="MBit" class="uri">MBit</a>, higher values require ‘1394BModeActive’<br />
to be set to 1 - and a camera and firewire controller which support 1394B mode<br />
and higher speeds than 400 <a href="MBit" class="uri">MBit</a>/s.<br />
‘GetCycleTimer’ Returns the current decoded 32-Bit firewire bus cycle count in<br />
return argument 1 and the <a href="GetSecs" class="uri">GetSecs</a>() time at which that count was queried in the<br />
second return argument: [firewireSeconds, <a href="GetSecsSeconds" class="uri">GetSecsSeconds</a>, busSeconds,<br />
busIsoCycles, busTicks]. A busIsoCycles takes 125 usecs, busTicks are 1/24.576<br />
Mhz on top of that. The combination of busSeconds, busIsoCycles and busTicks is<br />
decoded into firewireSeconds for your convenience. Firewire bus time wraps to<br />
zero every 128 seconds.<br />
‘ResetBus’ Resets the firewire or USB bus to which a camera is attached.<br />
‘ResetCamera’ Resets the camera.<br />
‘Temperature’ Retrieves and/or sets the target temperature (returned in 1st<br />
argument). Returns current temperature in 2nd return argument.<br />
‘WhiteBalance’ Get/Set white balance settings: 1st argument is U (in YUV mode)<br />
or Blue value (in RGB mode). 2nd argument is V (in YUV mode) or Red (in RGB<br />
mode). E.g., [u, v] = <a href="Screen" class="uri">Screen</a>(‘…’, camera, ‘WhiteBalance’ [, newU, newV]);<br />
‘WhiteShading’ Sets or gets white shading correction point: In/Out values 1, 2<br />
and 3 correspond to Red, Green and Blue, e.g., [r,g,b] = <a href="Screen" class="uri">Screen</a>(‘…’, camera,<br />
‘WhiteShading’ [, newR, newG, newB]);<br />
‘BaslerChecksumEnable’ Enable extra CRC checksumming on Basler cameras, to<br />
detect corrupt video frames. Compute intense!<br />
‘BaslerFrameTimestampEnable’ Use Basler cameras builtin timestamping of start of<br />
image exposure to compute extra precise capture timestamps. By default, the time<br />
of reception of a frame in the host computer is timestamped. Doesn’t work on<br />
many Basler cameras though.<br />
‘BaslerFrameCounterEnable’ Retrieve framecounter values from Basler camera<br />
itself instead of using our own software frame counter. Theoretically extra<br />
robust. In practice only useful if your Basler camera allows software controlled<br />
power-cycling, which some Basler cameras do not allow. If the camera doesn’t<br />
allow power-cycling then use of this feature will cause a hard hang of<br />
Psychtoolbox!<br />
‘LoadMarkerTrackingPlugin=’ Specify the name of a special markertracker plugin<br />
to load and use during video capture. The name must be the path and filename of<br />
a shared library which implements this plugin. EXPERIMENTAL and subject to<br />
change without notice!<br />
‘SendCommandToMarkerTrackingPlugin=’ Send an ASCII string containing commands to<br />
a loaded markertracker plugin. EXPERIMENTAL!</p>
<p>&lt;&lt;=====See also:===== OpenVideoCapture CloseVideoCapture StartVideoCapture StopVideoCapture GetCapturedImage &lt;&lt;</p>
